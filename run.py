# -*- coding: utf-8 -*-
"""Modulo3NLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cynropxBumb3b5HHiVoiyKmtmFEEbjWG

### Preparation
"""

# Packages to installfor sentiment analysis
!python -m textblob.download_corpora

# Install translator
!pip install translate

# Install google trans
!pip install googletrans==3.1.0a0

# Import all the libraries that are necessary for the three activities
from textblob import TextBlob
import json
import spacy
from spacy import displacy
from sklearn.model_selection import train_test_split
import googletrans
from googletrans import Translator
import translate

"""### Warm up: Out of the Box Sentiment Analysis """

# Class of sentiment analysis
class sentiment_analysis:

  def __init__(self, file):
    self.file = file

  def analysis(file):
    with open(file, "r") as data_file:
      for line in data_file:
          data = TextBlob(line.strip().split('<br />')[0])
          polarity = data.polarity
          if polarity < 0: 
            print("Negative")
          elif polarity >= 0:
            print("Positive")

# Calling the class function
analysis = sentiment_analysis.analysis("tiny_movie_reviews_dataset.txt")

"""### NER: Take a basic, pretrained NER model, and train further on a task-specific dataset"""

class ner:

  def __init__(self, file):
    self.file = file
  
  def ner_train(file):
    file = open(file)
    data = json.load(file)
    ner = spacy.load("en_core_web_sm")
    train, test = train_test_split(data["examples"], test_size=0.25)
    val, test = train_test_split(test, test_size=0.5)
    i = 0
    for i in range(len(train)):
      raw_text = train[i]
      text = ner(raw_text["content"])
      for word in text.ents:
        print(word.text,word.label_) # Print the words and the label assigned
      i += 1
    
    displacy.render(text,style="ent",jupyter=True) # Render the words with the tags assigned

ner.ner_train('Corona2.json')

"""### Set up and compare model performance of two different translation models"""

class traductor:

  def __init__(self, fileTest, fileRef):
    fileTest = self.fileTest
    fileRef = self.fileRef

  def traduction_library(fileTest, fileRef):
    translator2 = translate.Translator(from_lang="english",to_lang= "spanish")

    with open(fileTest, 'r') as fp:
      x = fp.readlines()[0:100]
      i= 0
      for i in range(100):
        translated = translator2.translate(x[i])
        i += 1

    with open(fileRef, 'r') as fp:
        y = fp.readlines()[0:100]

    return x, y

  def traduction_with_google(fileTest, fileRef):

    translator = Translator()

    with open(fileTest, 'r') as fp:
      x = fp.readlines()[0:100]
      i= 0
      for i in range(100):
        translated = translator.translate(x[i], src='en', dest='es')
        i += 1
  
    with open(fileRef, 'r') as fp:
        y = fp.readlines()[0:100]
        i = 0

    return x, y

  def score(trad, x, y):
    i = 0
    for i in range(100): 
      ref = y[i].split() 
      test = x[i].split()

    from nltk.translate.bleu_score import sentence_bleu
    i = 0
    for i in range(100): 
      ref = y[i].split() 
      test = x[i].split()

      i += 1
      print(f'{trad} TRANSLATOR: {sentence_bleu(ref, test)}')

x1, y1 = traductor.traduction_with_google("europarl-v7.es-en.en", "europarl-v7.es-en.es")

traductor.score("GOOGLE", x1, y1)

x2, y2 = traductor.traduction_library("europarl-v7.es-en.en", "europarl-v7.es-en.es")

traductor.score("LIBRARY", x1, y1)

